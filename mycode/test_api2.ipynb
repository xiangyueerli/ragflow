{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde618fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragflow_sdk import RAGFlow\n",
    "\n",
    "rag_object = RAGFlow(api_key=\"ragflow-FmMTM1OTNhNjkzNTExZjA5ZjA3MDI0Mm\", base_url=\"http://127.0.0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e12536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avatar': '', 'chunk_count': 87, 'chunk_method': 'naive', 'description': None, 'document_count': 6, 'embedding_model': 'text-embedding-3-small@OpenAI', 'id': 'd63690cc6edf11f0b3df0242ac180003', 'name': 'nianjin', 'pagerank': 0, 'parser_config': {'auto_keywords': 0, 'auto_questions': 0, 'chunk_token_num': 512, 'delimiter': '\\n', 'graphrag': {'use_graphrag': False}, 'html4excel': False, 'layout_recognize': 'Plain Text', 'raptor': {'use_raptor': False}}, 'permission': 'me', 'tenant_id': '34bdfbec68cf11f080d70242ac180006'}\n",
      "{'avatar': '', 'chunk_count': 35, 'chunk_method': 'naive', 'description': None, 'document_count': 23, 'embedding_model': 'text-embedding-3-small@OpenAI', 'id': '44bfe99268cf11f0a7220242ac180006', 'name': 'musique', 'pagerank': 0, 'parser_config': {'auto_keywords': 0, 'auto_questions': 0, 'chunk_token_num': 512, 'delimiter': '\\n', 'graphrag': {'community': False, 'entity_types': ['organization', 'person', 'geo', 'event', 'category'], 'method': 'light', 'resolution': True, 'use_graphrag': True}, 'html4excel': False, 'layout_recognize': 'Plain Text', 'raptor': {'use_raptor': False}}, 'permission': 'me', 'tenant_id': '34bdfbec68cf11f080d70242ac180006'}\n"
     ]
    }
   ],
   "source": [
    "# list dataset\n",
    "\n",
    "for dataset in rag_object.list_datasets():\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94497972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avatar': '', 'chunk_count': 87, 'chunk_method': 'naive', 'description': None, 'document_count': 6, 'embedding_model': 'text-embedding-3-small@OpenAI', 'id': 'd63690cc6edf11f0b3df0242ac180003', 'name': 'nianjin', 'pagerank': 0, 'parser_config': {'auto_keywords': 0, 'auto_questions': 0, 'chunk_token_num': 512, 'delimiter': '\\n', 'graphrag': {'use_graphrag': False}, 'html4excel': False, 'layout_recognize': 'Plain Text', 'raptor': {'use_raptor': False}}, 'permission': 'me', 'tenant_id': '34bdfbec68cf11f080d70242ac180006'}\n"
     ]
    }
   ],
   "source": [
    "# list dataset by id\n",
    "\n",
    "datasets = rag_object.list_datasets(id = \"44bfe99268cf11f0a7220242ac180006\")\n",
    "datasets = rag_object.list_datasets(id = \"d63690cc6edf11f0b3df0242ac180003\")\n",
    "\n",
    "print(datasets[0])\n",
    "dataset = datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4426677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"test.jsonl\" \n",
    "# file_path = \"merged_musique.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f294cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# upload documents to dataset\n",
    "import json\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "documents = []\n",
    "\n",
    "cnt = 0\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        data = json.loads(line.strip())\n",
    "        combined_text = f\"{data['title']}\\n{data['paragraph_text']}\"\n",
    "\n",
    "        # 创建临时文件\n",
    "        with tempfile.NamedTemporaryFile(\"w+\", delete=False, suffix=\".txt\", encoding=\"utf-8\") as tmp_file:\n",
    "            tmp_file.write(combined_text)\n",
    "            tmp_file_path = tmp_file.name\n",
    "\n",
    "        # 读取为二进制上传\n",
    "        with open(tmp_file_path, \"rb\") as bfile:\n",
    "            documents.append({\n",
    "                \"display_name\": f\"{idx}.txt\",\n",
    "                \"blob\": bfile.read()\n",
    "            })\n",
    "\n",
    "        # 删除临时文件\n",
    "        os.remove(tmp_file_path)\n",
    "        cnt += 1\n",
    "\n",
    "# 上传到 dataset\n",
    "dataset.upload_documents(documents)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e54ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update finished\n"
     ]
    }
   ],
   "source": [
    "# update documents to set meta_fields and chunk_method\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "# 获取所有文档\n",
    "docs = dataset.list_documents()\n",
    "\n",
    "# 遍历每个文档并添加 metadata（如果没有）\n",
    "for idx, doc in enumerate(docs):\n",
    "    # 若已有 metadata，不处理\n",
    "    if getattr(doc, \"meta_fields\", None):\n",
    "        continue\n",
    "\n",
    "    if idx >= len(raw_data):\n",
    "        print(f\"Warning: 原始数据不足，跳过 index {idx}\")\n",
    "        continue\n",
    "    \n",
    "    # 更新文档的 metadata 和 parser_config\n",
    "    doc.update({\n",
    "        \"meta_fields\": {\n",
    "            \"id\": cnt - idx - 1\n",
    "        },\n",
    "        \"chunk_method\": \"one\"\n",
    "    })\n",
    "\n",
    "print(\"Update finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6729847",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = dataset.list_documents()\n",
    "doc_ids = [doc.id for doc in docs]\n",
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e0eaec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete documents\n",
    "\n",
    "dataset.delete_documents(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f269d1ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Can't parse document that is currently being processed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# parse documents\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43masync_parse_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/ragflow/lib/python3.12/site-packages/ragflow_sdk/modules/dataset.py:86\u001b[39m, in \u001b[36mDataSet.async_parse_documents\u001b[39m\u001b[34m(self, document_ids)\u001b[39m\n\u001b[32m     84\u001b[39m res = res.json()\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res.get(\u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m) != \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(res.get(\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mException\u001b[39m: Can't parse document that is currently being processed"
     ]
    }
   ],
   "source": [
    "# parse documents\n",
    "\n",
    "dataset.async_parse_documents(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0626d395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始检索测试...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RAGFlow' object has no attribute 'retrieval_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 调用retrieval_test API\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m开始检索测试...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mrag_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieval_test\u001b[49m(\n\u001b[32m      4\u001b[39m     kb_id=dataset.id,\n\u001b[32m      5\u001b[39m     question=\u001b[33m\"\u001b[39m\u001b[33mWhat is the main topic of this document?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     top_k=\u001b[32m3\u001b[39m,\n\u001b[32m      7\u001b[39m     similarity_threshold=\u001b[32m0.2\u001b[39m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 打印结果\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m检索结果:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RAGFlow' object has no attribute 'retrieval_test'"
     ]
    }
   ],
   "source": [
    "# 调用retrieval_test API\n",
    "print(\"\\n开始检索测试...\")\n",
    "result = rag_object.retrieval_test(\n",
    "    kb_id=dataset.id,\n",
    "    question=\"What is the main topic of this document?\",\n",
    "    top_k=3,\n",
    "    similarity_threshold=0.2\n",
    ")\n",
    "\n",
    "# 打印结果\n",
    "print(\"\\n检索结果:\")\n",
    "for idx, chunk in enumerate(result.get('chunks', [])):\n",
    "    print(f\"[{idx+1}] 相似度: {chunk['score']:.4f}\")\n",
    "    print(f\"文档片段: {chunk['content']}\")\n",
    "    print(f\"来源文档: {chunk['doc_name']}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939abbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"code\": 0,\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"avatar\": \"\",\n",
      "      \"chunk_count\": 87,\n",
      "      \"chunk_method\": \"naive\",\n",
      "      \"create_date\": \"Fri, 01 Aug 2025 22:00:09 GMT\",\n",
      "      \"create_time\": 1754056809917,\n",
      "      \"created_by\": \"34bdfbec68cf11f080d70242ac180006\",\n",
      "      \"description\": null,\n",
      "      \"document_count\": 6,\n",
      "      \"embedding_model\": \"text-embedding-3-small@OpenAI\",\n",
      "      \"id\": \"d63690cc6edf11f0b3df0242ac180003\",\n",
      "      \"language\": \"English\",\n",
      "      \"name\": \"nianjin\",\n",
      "      \"pagerank\": 0,\n",
      "      \"parser_config\": {\n",
      "        \"auto_keywords\": 0,\n",
      "        \"auto_questions\": 0,\n",
      "        \"chunk_token_num\": 512,\n",
      "        \"delimiter\": \"\\n\",\n",
      "        \"graphrag\": {\n",
      "          \"use_graphrag\": false\n",
      "        },\n",
      "        \"html4excel\": false,\n",
      "        \"layout_recognize\": \"Plain Text\",\n",
      "        \"raptor\": {\n",
      "          \"use_raptor\": false\n",
      "        }\n",
      "      },\n",
      "      \"permission\": \"me\",\n",
      "      \"similarity_threshold\": 0.2,\n",
      "      \"status\": \"1\",\n",
      "      \"tenant_id\": \"34bdfbec68cf11f080d70242ac180006\",\n",
      "      \"token_num\": 45006,\n",
      "      \"update_date\": \"Fri, 01 Aug 2025 22:49:00 GMT\",\n",
      "      \"update_time\": 1754059740658,\n",
      "      \"vector_similarity_weight\": 0.3\n",
      "    },\n",
      "    {\n",
      "      \"avatar\": \"\",\n",
      "      \"chunk_count\": 35,\n",
      "      \"chunk_method\": \"naive\",\n",
      "      \"create_date\": \"Fri, 25 Jul 2025 04:46:26 GMT\",\n",
      "      \"create_time\": 1753389986944,\n",
      "      \"created_by\": \"34bdfbec68cf11f080d70242ac180006\",\n",
      "      \"description\": null,\n",
      "      \"document_count\": 23,\n",
      "      \"embedding_model\": \"text-embedding-3-small@OpenAI\",\n",
      "      \"id\": \"44bfe99268cf11f0a7220242ac180006\",\n",
      "      \"language\": \"English\",\n",
      "      \"name\": \"musique\",\n",
      "      \"pagerank\": 0,\n",
      "      \"parser_config\": {\n",
      "        \"auto_keywords\": 0,\n",
      "        \"auto_questions\": 0,\n",
      "        \"chunk_token_num\": 512,\n",
      "        \"delimiter\": \"\\n\",\n",
      "        \"graphrag\": {\n",
      "          \"community\": false,\n",
      "          \"entity_types\": [\n",
      "            \"organization\",\n",
      "            \"person\",\n",
      "            \"geo\",\n",
      "            \"event\",\n",
      "            \"category\"\n",
      "          ],\n",
      "          \"method\": \"light\",\n",
      "          \"resolution\": true,\n",
      "          \"use_graphrag\": true\n",
      "        },\n",
      "        \"html4excel\": false,\n",
      "        \"layout_recognize\": \"Plain Text\",\n",
      "        \"raptor\": {\n",
      "          \"use_raptor\": false\n",
      "        }\n",
      "      },\n",
      "      \"permission\": \"me\",\n",
      "      \"similarity_threshold\": 0.2,\n",
      "      \"status\": \"1\",\n",
      "      \"tenant_id\": \"34bdfbec68cf11f080d70242ac180006\",\n",
      "      \"token_num\": -2572,\n",
      "      \"update_date\": \"Fri, 01 Aug 2025 22:29:16 GMT\",\n",
      "      \"update_time\": 1754058556508,\n",
      "      \"vector_similarity_weight\": 0.3\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# curl --request GET \\\n",
    "#      --url http://127.0.0.1/api/v1/kb/44bfe99268cf11f0a7220242ac180006/knowledge_graph \\\n",
    "#      --header 'Authorization: Bearer ragflow-FmMTM1OTNhNjkzNTExZjA5ZjA3MDI0Mm'\n",
    "\n",
    "API_ENDPOINT = \"http://127.0.0.1/api/v1/datasets?page=1&page_size=10&orderby=create_time&desc=true\"\n",
    "API_TOKEN = \"ragflow-FmMTM1OTNhNjkzNTExZjA5ZjA3MDI0Mm\"  # 需通过登录接口获取\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(API_ENDPOINT, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    results = response.json()\n",
    "    print(json.dumps(results, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(f\"请求失败，状态码：{response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"code\": 401,\n",
      "  \"data\": null,\n",
      "  \"message\": \"<Unauthorized '401: Unauthorized'>\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# curl --request GET \\\n",
    "#      --url http://127.0.0.1/api/v1/kb/44bfe99268cf11f0a7220242ac180006/knowledge_graph \\\n",
    "#      --header 'Authorization: Bearer ragflow-FmMTM1OTNhNjkzNTExZjA5ZjA3MDI0Mm'\n",
    "\n",
    "API_ENDPOINT = \"http://127.0.0.1/v1/chunk/retrieval_test\"\n",
    "API_TOKEN = \"ragflow-FmMTM1OTNhNjkzNTExZjA5ZjA3MDI0Mm\"  # 需通过登录接口获取\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"question\": \"what is Grand\",\n",
    "    \"kb_id\": \"44bfe99268cf11f0a7220242ac180006\",\n",
    "}\n",
    "response = requests.post(API_ENDPOINT, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    results = response.json()\n",
    "    print(json.dumps(results, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(f\"请求失败，状态码：{response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01594292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 请求成功，返回数据：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset=\"utf-8\">\\n<meta name=\"viewport\" content=\"width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0\">\\n<meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\\n<link rel=\"shortcut icon\" href=\"/logo.svg\">\\n<title>RAGFlow</title>\\n<link rel=\"stylesheet\" href=\"/umi.0503d813.css\">\\n<script defer src=\"/iconfont.js\"></script>\\n</head>\\n<body>\\n<div id=\"root\"></div>\\n<script src=\"/umi.3cb0f58d.js\"></script>\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_ENDPOINT = \"http://127.0.0.1/get\"  # 根据你的路由定义，路径就是 /get\n",
    "API_TOKEN = \"ragflow-FmMTM1OTNhNjkzNTExZjA5ZjA3MDI0Mm\"  # 需通过登录接口获取\n",
    "\n",
    "CHUNK_ID = \"123\"  # 替换成你要查询的 chunk_id\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"chunk_id\": CHUNK_ID\n",
    "}\n",
    "\n",
    "response = requests.get(API_ENDPOINT, headers=headers, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"✅ 请求成功，返回数据：\")\n",
    "else:\n",
    "    print(f\"❌ 请求失败，状态码：{response.status_code}\")\n",
    "    print(\"响应内容：\", response.text)\n",
    "response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e35587",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rule in app.url_map.iter_rules():\n",
    "    print(rule.endpoint, rule.methods, rule.rule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
